<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Exploring the PyTorch Journey with a Deeper Dive</title>
    <link href="/2024/04/22/Pytoch/"/>
    <url>/2024/04/22/Pytoch/</url>
    
    <content type="html"><![CDATA[<p>路漫漫其修远兮。</p><span id="more"></span><!-- It's ashamed to realized the importance of systematically learning PyTorch now. However, there will never be an earlier time than today, so I will try my best start learning from now on. Reference materials include: --><ul><li><a href="https://pytorch-cn.readthedocs.io/zh/latest/">PyTorch官方文档(中文版)</a></li><li><a href="https://pytorch.org/tutorials/">tutorials</a></li><li><a href="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/">PyTorch教程书《Deep learning with PyTorch》</a></li></ul><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p><strong>PyTorch是一个使用Python格式实现深度学习模型的库</strong>。它的核心数据结构Tensor，是一个多维数组。Pytorch就像是一个能在GPU上运行并且自带自动求导功能的Numpy数组。它配备了高性能的C++运行引擎使得他不必依赖Python的运行机制：</p><ul><li><strong>Pytorch</strong>的很大部分使用C++和CUDA（NVIDIA提供的类似C++的语言）编写。</li><li><strong>PyTorch</strong>核心是提供多维数组（tensor）的库， torch模块提供了对其进行扩展操作的库。</li><li>同时<strong>PyTorch</strong>的第二个核心功能是允许Tensor跟踪对其所执行的操作，并通过反向传播来计算输出相对于其任何输入的导数。</li></ul><p><strong>PyTorch</strong>最先实现了深度学习架构，深度学习模型强大的原因是因为它可以自动的学习样本输出与所期望输出之间的关系。</p><h3 id="1-1-PyTorch提供了构建和训练神经网络所需的所有模块："><a href="#1-1-PyTorch提供了构建和训练神经网络所需的所有模块：" class="headerlink" title="1.1 PyTorch提供了构建和训练神经网络所需的所有模块："></a>1.1 PyTorch提供了构建和训练神经网络所需的所有模块：</h3><ul><li>构建神经网络的核心模块位于<code>troch.nn</code>中。包括全连接层、卷积层、激活函数和损失函数。</li><li><code>torch.util.data</code>能找到适用于数据加载和处理的工具，相关的两个主要的类为Dataset和DataLoader。<br>  -<code>Dataset</code>承担了自定义的数据格式与标准的Pytorch张量之间的转换任务<br>  -<code>DataLoader</code>可以在后台生成子进程来从Dataset中加载数据，使数据准备就绪并在循环可以使用后立即等待训练循环<br>  -除此之外还可以使用专用的硬件（多个GPU）来训练模型，在这些情况下，可以通过<code>torch.nn.DataParallel</code>和<code>torch.distributed</code>来使用其他的可用硬件</li></ul><p>Pytorch使用Caffe2作为后端，增加了对ONNX的支持（定义了一种与深度学习库无关的模型描述和转换格式），增加了称为<strong>TorchScript</strong>的延迟执行图模式运行引擎（这个模块避开了Python解释器所带来的成本，我们可以将这个模型看作是具有针对张量操作的有限指令集的虚拟机，它的调用不会增加Python的开销，还能使PyTorch可以实时地将已知序列转换为更有效的混合操作）。默认的运行方式是即使执行（eager mode）。</p><p><strong>关于PyTorch的安装，windows建议使用Anaconda，Linux建议使用Pip。</strong></p><h2 id="2-从张量开始"><a href="#2-从张量开始" class="headerlink" title="2. 从张量开始"></a>2. 从张量开始</h2><p><strong>- Tensor是Pytorch最基本的数据结构</strong></p><p>深度学习的应用往往是将某种形式获取的数据（图像或文本）转换为另一种形式的数据（标签、数字或文本），因此从这个角度看，深度学习就像是构建一个将数据从一种表示转换为另一种表示的系统，这种转换是通过从一系列样本中提取共性来驱动的额，这些共性能够反映期望的映射关系。<br>为了实现上述过程，首先需要让网路理解输入数据，因此输入需要被转换为浮点数的集合。这些浮点数的集合及其操作是现代AI的核心。而网络层次之间的数据被视为中间表示（intermediate representation）。中间表示是将输入与前一层神经元权重相结合的结果，每个中间表示对于之前的输入都是唯一的。<br>为此，PyTorch引入了一个基本的数据结构：张量（tensor）。张量是指将向量（vector）和矩阵（matrix）推广到任意维度，与张量相同概念的另一个名称是多维数组（multidimensional array）。</p><h3 id="2-1-张量基础"><a href="#2-1-张量基础" class="headerlink" title="2.1 张量基础"></a>2.1 张量基础</h3><p>Python列表或数字元组（tuple）是在内存中单独分配的Python对象的集合；而PyTorch张量或NumPy数组（通常）是连续内存块上的视图（view），这些内存块存有未封装（unboxed）的C数值类型。<br><strong>获取一个张量的形状：tensor.shape</strong></p><h3 id="2-2-张量与存储"><a href="#2-2-张量与存储" class="headerlink" title="2.2 张量与存储"></a>2.2 张量与存储</h3><p>基础内存只分配一次，由torch.Storage实例管理，<strong>Storage是一个一维的数值数据数组</strong>，例如一块包含了指定类型（可能是float或int32）数字的连续内存块。<strong>而tensor可以看作是某个Storage实例的视图。</strong>因此多个tensor可以索引到同一Storage。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">import torch<br>points = torch.tensor([[1.0, 4.0], [2.0, 1.0], [3.0, 5.0]])<br>points.storage()<br><br><span class="hljs-comment"># 输出</span><br> 1.0<br> 4.0<br> 2.0<br> 1.0<br> 3.0<br> 5.0<br>[torch.FloatStorage of size 6]<br></code></pre></td></tr></table></figure><p><strong>无法使用两个索引来索引二维tensor的存储，因为Storage始终是一维的，与引用它的任何张量的维数无关。</strong></p><p><img src="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/img/chapter2/2.4.png" alt="张量是一个存储实例的视图"></p><h3 id="2-3-尺寸、存储偏移与步长"><a href="#2-3-尺寸、存储偏移与步长" class="headerlink" title="2.3 尺寸、存储偏移与步长"></a>2.3 尺寸、存储偏移与步长</h3><p><img src="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/img/chapter2/2.5.png" alt="张量的尺寸、偏移与步长之间的关系"><br>tensor可以看作是某个Storage实例的视图。为了索引Storage，张量依赖于几条明确定义它们的信息：尺寸（size）、存储偏移（storage offset）和步长（stride）</p><ul><li>尺寸是一个元组，表示tensor每个维度上有多少个元素。</li><li>存储偏移是Storage中与张量中的第一个元素相对应的索引。</li><li>步长是在Storage中为了沿每个维度获取下一个元素而需要跳过的元素数量。<ul><li>步长是一个元组，表示当索引在每个维度上增加1时必须跳过的存储中元素的数量。</li></ul></li><li>shape是属性，size()是类，这俩包含的信息相同。</li></ul><p>用下标<code>i</code>和<code>j</code>访问二维张量等价于访问存储中的<code>storage_offset + stride[0] * i + stride[1] * j</code>元素。</p><p>张量Tensor和和存储Storage之间的这种间接操作会使某些操作（例如转置或提取子张量）的代价很小，因为<strong>它们不会导致内存重新分配</strong>；相反，它们（仅仅）分配一个新的张量对象，该对象具有不同的尺寸、存储偏移或步长。更改子张量同时也会对原始张量产生影响。所以我们可以克隆子张量得到新的张量（以避免这种影响）：<code>tensor.clone()</code>.Tensor的转置只改变尺寸和步长。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">some_tensor = torch.ones(3, 4, 5)<br>some_tensor.shape, some_tensor.stride()<br><span class="hljs-comment"># 输出</span><br>(torch.Size([3, 4, 5]), (20, 5, 1))<br><br>some_tensor_t = some_tensor.transpose(0, 2)<br>some_tensor_t.shape, some_tensor_t.stride()<br><span class="hljs-comment"># 输出</span><br>(torch.Size([5, 4, 3]), (1, 5, 20))<br></code></pre></td></tr></table></figure><h3 id="2-4-数据类型"><a href="#2-4-数据类型" class="headerlink" title="2.4 数据类型"></a>2.4 数据类型</h3><!-- ### Run server<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a> –&gt;<br> –&gt;</p>]]></content>
    
    
    
    <tags>
      
      <tag>code</tag>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
