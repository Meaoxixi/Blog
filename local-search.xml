<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Configure online demo</title>
    <link href="/2024/05/19/onlineDemo/"/>
    <url>/2024/05/19/onlineDemo/</url>
    
    <content type="html"><![CDATA[<p>这篇文章总共纪录了学习Replicate和HuggingFace在线搭demo的过程，最终我选的是HuggingFace，所以HuggingFace的内容详尽一些，Replicate只有一点点。</p><span id="more"></span><h1 id="Replicate"><a href="#Replicate" class="headerlink" title="Replicate"></a>Replicate</h1><p>参考：<a href="https://replicate.com/docs">Replicate文档</a><br>Replicate是一个云端的机器学习模型运行平台，它允许用户使用云端API（在Python或Jupyter Notebook中）直接运行模型，并在云端进行模型的部署和调优。<br>其优势在于：<br>    - 无需下载、安装或配置<br>    - 快速轻松运行机器学习模型<br>    - 提供大量的预训练模型和数据集</p><h2 id="1-1-大致流程"><a href="#1-1-大致流程" class="headerlink" title="1.1 大致流程"></a>1.1 大致流程</h2><p>Replicate的HTTP API 可与任何编程语言配合使用。使用 Python 客户端，首先需要安装Python库：<code>pip install replicate</code>。</p><p>然后去<a href="https://replicate.com/account/api-tokens">account settings</a>中找到你的API token，并把它设置（声明）到你当前的代码环境：<code>export REPLICATE_API_TOKEN=&lt;paste-your-token-here&gt;</code>。</p><p>安全一点的方式为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># get a token: https://replicate.com/account</span><br><span class="hljs-keyword">from</span> getpass <span class="hljs-keyword">import</span> getpass<br><span class="hljs-keyword">import</span> os<br><br>REPLICATE_API_TOKEN = getpass()<br>os.environ[<span class="hljs-string">&quot;REPLICATE_API_TOKEN&quot;</span>] = REPLICATE_API_TOKEN<br><br><span class="hljs-comment">## 2.1 在Python代码中导入Replicate库，以便使用Replicate的功能</span><br><span class="hljs-keyword">import</span> replicate<br><span class="hljs-comment">### receive images as inputs. Use a file handle or URL:</span><br>image = <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;mystery.jpg&quot;</span>, <span class="hljs-string">&quot;rb&quot;</span>)<br><span class="hljs-comment">### or...</span><br>image = <span class="hljs-string">&quot;https://example.com/mystery.jpg&quot;</span><br><br><span class="hljs-comment">## 2.2 调用模型，按需求返回</span><br>replicate.run(<br>  <span class="hljs-string">&quot;replicate/resnet:dd782a3d531b61af491d1026434392e8afb40bfb53b8af35f727e80661489767&quot;</span>,<br>  <span class="hljs-built_in">input</span>=&#123;<span class="hljs-string">&quot;image&quot;</span>: image&#125;<br>)<br></code></pre></td></tr></table></figure><p><a href="https://juejin.cn/post/7298642789078974515">有个跟我很像的用了controlnet的工作在Replicate上的部署教程</a><br>大概了解了一下，感觉Replicate挺简单的，但是好像不如Huggingface的使用者多以及GPU算力要贵一点。决定临阵倒戈，还是去学HuggingFace吧，谁知道以后遇到什么bug了能不能解决。</p><p>好多人用啊，让我看看这个最大的开源平台有多牛(ง๑ •̀_•́)ง</p><h1 id="Gradio-HuggingFace"><a href="#Gradio-HuggingFace" class="headerlink" title="Gradio + HuggingFace"></a>Gradio + HuggingFace</h1><p>计算机视觉和图像处理的算法一般都具有直观的实用性。为了推广自己工作的影响力，大家会选择把自己算法的实现效果部署到网页端的UI接口供大家使用。</p><h2 id="1-界面设计库Gradio"><a href="#1-界面设计库Gradio" class="headerlink" title="1 界面设计库Gradio"></a>1 界面设计库Gradio</h2><p>Gradio是MIT的开源项目，它允许我们快速建立demo或者web application。使用时可理解为一个Python包，Prerequisite: Gradio requires Python 3.8 or higher，它的安装命令：<code>pip install gradio</code>。<br><a href="https://www.gradio.app/guides/quickstart">Gradio教程</a><br><a href="https://www.gradio.app/docs/">Gradio文档</a></p><h3 id="1-1-示例，实现一个本地静态交互页面"><a href="#1-1-示例，实现一个本地静态交互页面" class="headerlink" title="1.1 示例，实现一个本地静态交互页面"></a>1.1 示例，实现一个本地静态交互页面</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">greet</span>(<span class="hljs-params">name, intensity</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Hello, &quot;</span> + name + <span class="hljs-string">&quot;!&quot;</span> * <span class="hljs-built_in">int</span>(intensity)<br><br>demo = gr.Interface(<br>    fn=greet,<br>    inputs=[<span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;slider&quot;</span>],<br>    outputs=[<span class="hljs-string">&quot;text&quot;</span>],<br>)<br><br>demo.launch()<br><br></code></pre></td></tr></table></figure><p>我用的anaconda命令行运行，它显示：</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs lasso">Running <span class="hljs-keyword">on</span> <span class="hljs-built_in">local</span> URL:  http:<span class="hljs-comment">//127.0.0.1:7860</span><br><br><span class="hljs-keyword">To</span> create a <span class="hljs-keyword">public</span> <span class="hljs-keyword">link</span>, <span class="hljs-built_in">set</span> <span class="hljs-string">`share=True`</span> <span class="hljs-keyword">in</span> <span class="hljs-string">`launch()`</span>.<br></code></pre></td></tr></table></figure><p>然后我在本地浏览器输入<a href="http://127.0.0.1:7788/%E5%B0%B1%E7%9C%8B%E5%88%B0%E4%BA%86%E5%AF%B9%E5%BA%94%E7%9A%84%E9%A1%B5%E9%9D%A2%E3%80%82">http://127.0.0.1:7788/就看到了对应的页面。</a></p><h3 id="1-2-hot-reload-mode"><a href="#1-2-hot-reload-mode" class="headerlink" title="1.2 hot reload mode"></a>1.2 hot reload mode</h3><p>Automatically reloads the Gradio app whenever you make changes to the file. To do this, simply type in gradio before the name of the file instead of python. In the example:<code>gradio app.py</code>(Type this in terminal).<br><a href="https://www.gradio.app/guides/developing-faster-with-reload-mode">Hot Reloading Guide</a></p><h3 id="1-3-Understanding-the-Interface-Class"><a href="#1-3-Understanding-the-Interface-Class" class="headerlink" title="1.3 Understanding the Interface Class"></a>1.3 Understanding the Interface Class</h3><p>The Interface class is designed to create demos for machine learning models which accept one or more inputs, and return one or more outputs.<br>它主要有三个核心属性：</p><ul><li><code>fn</code>: the function to wrap a user interface (UI) around</li><li><code>inputs</code>：the number of components should match the number of arguments in your function</li><li><code>outputs</code>：the number of components should match the number of return values from your function.</li></ul><p><a href="https://www.gradio.app/main/guides/the-interface-class">building Interfaces</a></p><h3 id="1-4-Sharing-Your-Demo"><a href="#1-4-Sharing-Your-Demo" class="headerlink" title="1.4 Sharing Your Demo"></a>1.4 Sharing Your Demo</h3><p>Gradio lets you easily share a machine learning demo without having to worry about the hassle of hosting on a web server. Simply set <code>share=True</code> in launch() like <code>demo.launch(share=True)</code>, and a publicly accessible URL will be created for your demo.</p><p>所以实际上他跑起来用的是我本地的算力资源，但是类似网络通信可以在不同电脑之间进行联络。</p><h2 id="2-在线托管平台-HuggingFace"><a href="#2-在线托管平台-HuggingFace" class="headerlink" title="2 在线托管平台 HuggingFace"></a>2 在线托管平台 HuggingFace</h2><p>在本地测试完成后，接下来就是考虑如何将程序发布到在线平台的问题了。HuggingFace提供了一个项目托管平台，而且能免费提供如Google Colab的在线计算资源。使用服务前，先注册账号（官网界面右上角”Sign Up”）。</p><h3 id="2-1-在线计算空间-Space"><a href="#2-1-在线计算空间-Space" class="headerlink" title="2.1 在线计算空间:Space"></a>2.1 在线计算空间:Space</h3><p>在HuggingFace官网登录账号后，切换到Spaces创建一个新的空间。记得选中”Gradio”和”Public”，以生成一个可公开使用的Gradio在线应用。每个项目空间免费配备8个CPU核和16GB 运行内存，GPU资源需要单独付费。更多关于Spaces的介绍可参考<a href="https://huggingface.co/docs/hub/spaces">官方文档</a>。<br>创建完Space之后，我们需要把本地项目文件（UI构建文件必须得命名成app.py且位于根目录）上传到该空间。具体方法与Github项目的上传和版本维护方式完全一样:</p><ul><li>克隆space项目到本地：<code>git clone https://huggingface.co/spaces/your_account/proj_name/tree/main</code></li><li>将本地已跑通的项目文件复制到刚才克隆的space项目文件夹</li><li>新建描述运行环境依赖的文件：<code>requirements.txt</code></li><li>指定Python依赖的包:<code>packages.txt</code></li><li>指定特殊的系统依赖配置</li><li><a href="https://huggingface.co/docs/hub/spaces-dependencies">详情参考</a></li><li>将此更新同步到远程仓库：<ul><li>git add -A .</li><li>git commit -m “add project files”</li><li>git push</li></ul></li></ul><p>完成以上步骤后（等待1~2分钟系统刷新），进入Space项目的App选项卡即可查看部署到web端的应用。</p><h3 id="2-2-模型托管仓库-Models"><a href="#2-2-模型托管仓库-Models" class="headerlink" title="2.2 模型托管仓库:Models"></a>2.2 模型托管仓库:Models</h3><p>如果我们运行的程序是AI模型，那么一般需要提供一个训练好的checkpoint（一般上百兆）供在线加载。这时，我们可以在HuggingFace的Models页面创建一个与Space项目同名的模型仓库，用于存储需要的checkpoint等文件。</p><ul><li>上传文件：通过上文提到的git方式，或者直接点击已创建的模型页面的Add file</li><li>获取文件路径：例如上传到模型仓库的文件路径是：<code>https://huggingface.co/menghanxia/disco/tree/main/model.pth.tar</code>，其对应的下载路径则需要将tree修改为resolve，即<code>https://huggingface.co/menghanxia/disco/resolve/main/disco-beta.pth.tar</code></li><li>在Space项目的app.py文件中调用文件下载命令:<code>os.system(&quot;wget https://huggingface.co/menghanxia/disco/resolve/main/disco-beta.pth.rar&quot;)</code></li></ul><p><a href="https://huggingface.co/docs/hub/spaces">Spaces文档</a><br><a href="https://blog.csdn.net/SoulmateY/article/details/117327898">CSDN博文</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Tutorial</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Exploring the PyTorch Journey with a Deeper Dive</title>
    <link href="/2024/04/22/Pytoch/"/>
    <url>/2024/04/22/Pytoch/</url>
    
    <content type="html"><![CDATA[<p>路漫漫其修远兮。</p><span id="more"></span><!-- It's ashamed to realized the importance of systematically learning PyTorch now. However, there will never be an earlier time than today, so I will try my best start learning from now on.  --><p>Reference materials include:</p><ul><li><a href="https://pytorch-cn.readthedocs.io/zh/latest/">PyTorch官方文档(中文版)</a></li><li><a href="https://pytorch.org/tutorials/">tutorials</a></li><li><a href="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/">PyTorch教程书《Deep learning with PyTorch》</a></li></ul><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p><strong>PyTorch是一个使用Python格式实现深度学习模型的库</strong>。它的核心数据结构Tensor，是一个多维数组。Pytorch就像是一个能在GPU上运行并且自带自动求导功能的Numpy数组。它配备了高性能的C++运行引擎使得他不必依赖Python的运行机制：</p><ul><li><strong>Pytorch</strong>的很大部分使用C++和CUDA（NVIDIA提供的类似C++的语言）编写。</li><li><strong>PyTorch</strong>核心是提供多维数组（tensor）的库， torch模块提供了对其进行扩展操作的库。</li><li>同时<strong>PyTorch</strong>的第二个核心功能是允许Tensor跟踪对其所执行的操作，并通过反向传播来计算输出相对于其任何输入的导数。</li></ul><p><strong>PyTorch</strong>最先实现了深度学习架构，深度学习模型强大的原因是因为它可以自动的学习样本输出与所期望输出之间的关系。</p><h3 id="1-1-PyTorch提供了构建和训练神经网络所需的所有模块："><a href="#1-1-PyTorch提供了构建和训练神经网络所需的所有模块：" class="headerlink" title="1.1 PyTorch提供了构建和训练神经网络所需的所有模块："></a>1.1 PyTorch提供了构建和训练神经网络所需的所有模块：</h3><ul><li>构建神经网络的核心模块位于<code>troch.nn</code>中。包括全连接层、卷积层、激活函数和损失函数。</li><li><code>torch.util.data</code>能找到适用于数据加载和处理的工具，相关的两个主要的类为Dataset和DataLoader。<br>  -<code>Dataset</code>承担了自定义的数据格式与标准的Pytorch张量之间的转换任务<br>  -<code>DataLoader</code>可以在后台生成子进程来从Dataset中加载数据，使数据准备就绪并在循环可以使用后立即等待训练循环<br>  -除此之外还可以使用专用的硬件（多个GPU）来训练模型，在这些情况下，可以通过<code>torch.nn.DataParallel</code>和<code>torch.distributed</code>来使用其他的可用硬件</li></ul><p>Pytorch使用Caffe2作为后端，增加了对ONNX的支持（定义了一种与深度学习库无关的模型描述和转换格式），增加了称为<strong>TorchScript</strong>的延迟执行图模式运行引擎（这个模块避开了Python解释器所带来的成本，我们可以将这个模型看作是具有针对张量操作的有限指令集的虚拟机，它的调用不会增加Python的开销，还能使PyTorch可以实时地将已知序列转换为更有效的混合操作）。默认的运行方式是即使执行（eager mode）。</p><p><strong>关于PyTorch的安装，windows建议使用Anaconda，Linux建议使用Pip。</strong></p><h2 id="2-从张量开始"><a href="#2-从张量开始" class="headerlink" title="2. 从张量开始"></a>2. 从张量开始</h2><p><strong>- Tensor是Pytorch最基本的数据结构</strong></p><p>深度学习的应用往往是将某种形式获取的数据（图像或文本）转换为另一种形式的数据（标签、数字或文本），因此从这个角度看，深度学习就像是构建一个将数据从一种表示转换为另一种表示的系统，这种转换是通过从一系列样本中提取共性来驱动的额，这些共性能够反映期望的映射关系。<br>为了实现上述过程，首先需要让网路理解输入数据，因此输入需要被转换为浮点数的集合。这些浮点数的集合及其操作是现代AI的核心。而网络层次之间的数据被视为中间表示（intermediate representation）。中间表示是将输入与前一层神经元权重相结合的结果，每个中间表示对于之前的输入都是唯一的。<br>为此，PyTorch引入了一个基本的数据结构：张量（tensor）。张量是指将向量（vector）和矩阵（matrix）推广到任意维度，与张量相同概念的另一个名称是多维数组（multidimensional array）。</p><h3 id="2-1-张量基础"><a href="#2-1-张量基础" class="headerlink" title="2.1 张量基础"></a>2.1 张量基础</h3><p>Python列表或数字元组（tuple）是在内存中单独分配的Python对象的集合；而PyTorch张量或NumPy数组（通常）是连续内存块上的视图（view），这些内存块存有未封装（unboxed）的C数值类型。<br><strong>获取一个张量的形状：tensor.shape</strong></p><h3 id="2-2-张量与存储"><a href="#2-2-张量与存储" class="headerlink" title="2.2 张量与存储"></a>2.2 张量与存储</h3><p>基础内存只分配一次，由torch.Storage实例管理，<strong>Storage是一个一维的数值数据数组</strong>，例如一块包含了指定类型（可能是float或int32）数字的连续内存块。<strong>而tensor可以看作是某个Storage实例的视图。</strong>因此多个tensor可以索引到同一Storage。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br>points = torch.tensor([[<span class="hljs-number">1.0</span>, <span class="hljs-number">4.0</span>], [<span class="hljs-number">2.0</span>, <span class="hljs-number">1.0</span>], [<span class="hljs-number">3.0</span>, <span class="hljs-number">5.0</span>]])<br>points.storage()<br><br><span class="hljs-comment"># 输出</span><br> <span class="hljs-number">1.0</span><br> <span class="hljs-number">4.0</span><br> <span class="hljs-number">2.0</span><br> <span class="hljs-number">1.0</span><br> <span class="hljs-number">3.0</span><br> <span class="hljs-number">5.0</span><br>[torch.FloatStorage of size <span class="hljs-number">6</span>]<br></code></pre></td></tr></table></figure><p> <strong>无法使用两个索引来索引二维tensor的存储，因为Storage始终是一维的，与引用它的任何张量的维数无关。</strong><br><img src="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/img/chapter2/2.4.png" alt="张量是一个存储实例的视图"></p><h3 id="2-3-尺寸、存储偏移与步长"><a href="#2-3-尺寸、存储偏移与步长" class="headerlink" title="2.3 尺寸、存储偏移与步长"></a>2.3 尺寸、存储偏移与步长</h3><p><img src="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/img/chapter2/2.5.png" alt="张量的尺寸、偏移与步长之间的关系"><br>tensor可以看作是某个Storage实例的视图。为了索引Storage，张量依赖于几条明确定义它们的信息：尺寸（size）、存储偏移（storage offset）和步长（stride）<br>    - 尺寸是一个元组，表示tensor每个维度上有多少个元素。<br>    - 存储偏移是Storage中与张量中的第一个元素相对应的索引。<br>        - 步长是在Storage中为了沿每个维度获取下一个元素而需要跳过的元素数量。<br>        - 步长是一个元组，表示当索引在每个维度上增加1时必须跳过的存储中元素的数量。<br>    - shape是属性，size()是类，这俩包含的信息相同。</p><p>用下标<code>i</code>和<code>j</code>访问二维张量等价于访问存储中的<code>storage_offset + stride[0] * i + stride[1] * j</code>元素。<br>张量Tensor和和存储Storage之间的这种间接操作会使某些操作（例如转置或提取子张量）的代价很小，因为<strong>它们不会导致内存重新分配</strong>；相反，它们（仅仅）分配一个新的张量对象，该对象具有不同的尺寸、存储偏移或步长。更改子张量同时也会对原始张量产生影响。所以我们可以克隆子张量得到新的张量（以避免这种影响）：<code>tensor.clone()</code>.Tensor的转置只改变尺寸和步长。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">some_tensor = torch.ones(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>)<br>some_tensor.shape, some_tensor.stride()<br><span class="hljs-comment"># 输出</span><br>(torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]), (<span class="hljs-number">20</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>))<br><br>some_tensor_t = some_tensor.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>)<br>some_tensor_t.shape, some_tensor_t.stride()<br><span class="hljs-comment"># 输出</span><br>(torch.Size([<span class="hljs-number">5</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>]), (<span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">20</span>))<br><br></code></pre></td></tr></table></figure><h3 id="2-4-数据类型"><a href="#2-4-数据类型" class="headerlink" title="2.4 数据类型"></a>2.4 数据类型</h3><!-- ### Run server<!-- ### Run server<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a> –&gt;<br> –&gt;</p>]]></content>
    
    
    
    <tags>
      
      <tag>code</tag>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
