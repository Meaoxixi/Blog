<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>PyTorch_《Tutorials》</title>
    <link href="/2024/05/29/Pytorch_1/"/>
    <url>/2024/05/29/Pytorch_1/</url>
    
    <content type="html"><![CDATA[<p>路漫漫其修远兮。</p><span id="more"></span><p>Reference materials include:</p><ul><li><a href="https://pytorch-cn.readthedocs.io/zh/latest/">PyTorch官方文档(中文版)</a></li><li><a href="https://pytorch.org/tutorials/">Tutorials</a></li><li>Andrew W. Traska撰写的<a href="https://www.manning.com/books/grokking-deep-learning">《Grokking Deep Learning》</a>是开发强大模型和理解深度神经网络基础机制的重要资源</li><li>Ian Goodfellow, Yoshua Bengio和Aaron Courville的<a href="https://www.deeplearningbook.org/">《Deep Learning》</a></li><li>清华翻译的<a href="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/">《Deep learning with PyTorch》</a></li></ul><p>本篇章主要记录的是官网提供的<a href="https://pytorch.org/tutorials/">tutorials</a>，是Pytorch探索之旅的第2篇章啦！</p><h1 id="Quickstart"><a href="#Quickstart" class="headerlink" title="Quickstart"></a>Quickstart</h1><h2 id="Working-with-data"><a href="#Working-with-data" class="headerlink" title="Working with data"></a>Working with data</h2><p>PyTorch has two primitives to work with data: <code>torch.utils.data.DataLoader</code> and <code>torch.utils.data.Dataset</code>. <strong>Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset.</strong> PyTorch offers domain-specific libraries such as TorchText, TorchVision, and TorchAudio, all of which include datasets. The torchvision.datasets module contains Dataset objects for many real-world vision data like CIFAR, COCO (<a href="https://pytorch.org/vision/stable/datasets.html">full list here</a>).<br>Every TorchVision Dataset includes two arguments: <code>transform</code> and <code>target_transform</code> to modify the samples and labels respectively.</p><h2 id="Creating-Models"><a href="#Creating-Models" class="headerlink" title="Creating Models"></a>Creating Models</h2><p>To define a neural network in PyTorch, we create a class that inherits from nn.Module. </p><ul><li>We define the layers of the network in the <code>__init__</code> function</li><li>Specify how data will pass through the network in the <code>forward</code> function</li><li>To accelerate operations in the neural network, we move it to the GPU or MPS if available.</li></ul><h2 id="Optimizing-the-Model-Parameters"><a href="#Optimizing-the-Model-Parameters" class="headerlink" title="Optimizing the Model Parameters"></a>Optimizing the Model Parameters</h2><p>To train a model, we need a loss function and an optimizer.</p><h2 id="Saving-Models"><a href="#Saving-Models" class="headerlink" title="Saving Models"></a>Saving Models</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.save(model.state_dict(), <span class="hljs-string">&quot;model.pth&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Saved PyTorch Model State to model.pth&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="Loading-Models"><a href="#Loading-Models" class="headerlink" title="Loading Models"></a>Loading Models</h2><p>The process for loading a model includes re-creating the model structure and loading the state dictionary into it.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">model = NeuralNetwork().to(device)<br>model.load_state_dict(torch.load(<span class="hljs-string">&quot;model.pth&quot;</span>))<br></code></pre></td></tr></table></figure><h1 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h1><p>Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators.</p><h2 id="Initializing-a-Tensor"><a href="#Initializing-a-Tensor" class="headerlink" title="Initializing a Tensor"></a>Initializing a Tensor</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 1. Directly from data</span><br>data = [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]]<br>x_data = torch.tensor(data)<br><br><span class="hljs-comment"># 2. From a NumPy array</span><br>np_array = np.array(data)<br>x_np = torch.from_numpy(np_array)<br><br><span class="hljs-comment"># 3. From another tensor</span><br>x_ones = torch.ones_like(x_data) <span class="hljs-comment"># retains the properties of x_data</span><br>x_rand = torch.rand_like(x_data, dtype=torch.<span class="hljs-built_in">float</span>) <span class="hljs-comment"># overrides the datatype of x_data</span><br><br><span class="hljs-comment"># 4. With random or constant values</span><br>shape = (<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,)<br>rand_tensor = torch.rand(shape)<br>ones_tensor = torch.ones(shape)<br>zeros_tensor = torch.zeros(shape)<br></code></pre></td></tr></table></figure><h2 id="Attributes-of-a-Tensor"><a href="#Attributes-of-a-Tensor" class="headerlink" title="Attributes of a Tensor"></a>Attributes of a Tensor</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs pythohn">print(f&quot;Shape of tensor: &#123;tensor.shape&#125;&quot;)<br>print(f&quot;Datatype of tensor: &#123;tensor.dtype&#125;&quot;)<br>print(f&quot;Device tensor is stored on: &#123;tensor.device&#125;&quot;)<br></code></pre></td></tr></table></figure><h2 id="Operations-on-Tensor"><a href="#Operations-on-Tensor" class="headerlink" title="Operations on Tensor"></a>Operations on Tensor</h2><p>Over 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing, indexing, slicing), sampling and more are comprehensively described <a href="https://pytorch.org/docs/stable/torch.html">here</a>.<br>By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using .to method (after checking for GPU availability). Keep in mind that copying large tensors across devices can be expensive in terms of time and memory!</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># We move our tensor to the GPU if available</span><br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    tensor = tensor.to(<span class="hljs-string">&quot;cuda&quot;</span>)<br><br><span class="hljs-comment"># 1 Standard numpy-like indexing and slicing</span><br>tensor = torch.ones(<span class="hljs-number">4</span>, <span class="hljs-number">4</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;First row: <span class="hljs-subst">&#123;tensor[<span class="hljs-number">0</span>]&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;First column: <span class="hljs-subst">&#123;tensor[:, <span class="hljs-number">0</span>]&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Last column: <span class="hljs-subst">&#123;tensor[..., -<span class="hljs-number">1</span>]&#125;</span>&quot;</span>)<br>tensor[:,<span class="hljs-number">1</span>] = <span class="hljs-number">0</span><br><span class="hljs-built_in">print</span>(tensor)<br><span class="hljs-comment">## 输出</span><br>First row: tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>])<br>First column: tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>])<br>Last column: tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>])<br>tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]])<br><br><span class="hljs-comment"># 2 Joining tensors</span><br><span class="hljs-comment"># - `torch.cat`: Concatenates the given sequence along an existing dimension.</span><br><span class="hljs-comment"># - `torch.stack`: Concatenates a sequence of tensors along a new dimension.</span><br><br><span class="hljs-comment"># 3 Single-element tensors </span><br><span class="hljs-comment"># If you have a one-element tensor, for example by aggregating all values of a tensor into one value, you can convert it to a Python numerical value using `item()`</span><br></code></pre></td></tr></table></figure><h2 id="Bridge-with-NumPy"><a href="#Bridge-with-NumPy" class="headerlink" title="Bridge with NumPy"></a>Bridge with NumPy</h2><p>Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Tensor to NumPy array</span><br>n = t.numpy()<br><span class="hljs-comment"># NumPy array to Tensor</span><br>t = torch.from_numpy(n)<br><br><span class="hljs-comment">## Changes in the NumPy array reflects in the tensor.</span><br>n = np.ones(<span class="hljs-number">5</span>)<br>t = torch.from_numpy(n)<br>np.add(n, <span class="hljs-number">1</span>, out=n)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;t: <span class="hljs-subst">&#123;t&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;n: <span class="hljs-subst">&#123;n&#125;</span>&quot;</span>)<br><span class="hljs-comment">### 输出</span><br>t: tensor([<span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>], dtype=torch.float64)<br>n: [<span class="hljs-number">2.</span> <span class="hljs-number">2.</span> <span class="hljs-number">2.</span> <span class="hljs-number">2.</span> <span class="hljs-number">2.</span>]<br></code></pre></td></tr></table></figure><h1 id="Datasets-and-DataLoaders"><a href="#Datasets-and-DataLoaders" class="headerlink" title="Datasets and DataLoaders"></a>Datasets and DataLoaders</h1><p><a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">https://pytorch.org/tutorials/beginner/basics/data_tutorial.html</a></p><h1 id="Transformers"><a href="#Transformers" class="headerlink" title="Transformers"></a>Transformers</h1><h1 id="Build-Model"><a href="#Build-Model" class="headerlink" title="Build Model"></a>Build Model</h1><h1 id="Automatic-Differentiation"><a href="#Automatic-Differentiation" class="headerlink" title="Automatic Differentiation"></a>Automatic Differentiation</h1><h1 id="Optimization-Loop"><a href="#Optimization-Loop" class="headerlink" title="Optimization Loop"></a>Optimization Loop</h1><h1 id="Save-Load-and-Use-Model"><a href="#Save-Load-and-Use-Model" class="headerlink" title="Save, Load and Use Model"></a>Save, Load and Use Model</h1>]]></content>
    
    
    <categories>
      
      <category>Tutorial</category>
      
      <category>PyTorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Userful tools</title>
    <link href="/2024/05/22/Userful-tools/"/>
    <url>/2024/05/22/Userful-tools/</url>
    
    <content type="html"><![CDATA[<p>工欲善其事必先利其器</p><span id="more"></span><h1 id="1-笔记管理"><a href="#1-笔记管理" class="headerlink" title="1 笔记管理"></a>1 笔记管理</h1><p><a href="https://www.notion.so/">Notion</a></p><h1 id="2-作图"><a href="#2-作图" class="headerlink" title="2 作图"></a>2 作图</h1><p>大家好像主要都是Visio，PPT为辅（我觉得PhotoShop也很方便，嘻嘻嘻感觉冥冥之中当年钻研摄影帮了我好多好多）</p><h2 id="2-1-首先是工具推荐"><a href="#2-1-首先是工具推荐" class="headerlink" title="2.1 首先是工具推荐"></a>2.1 首先是工具推荐</h2><ul><li><a href="https://app.diagrams.net/">draw.io</a></li><li><a href="https://github.com/guanyingc/latex_paper_writing_tips">Tips for Writing a Research Paper using LaTeX</a>:由陈冠英老师维护，给LaTeX初学者提供多个图表排版的例子，方便用到自己的论文当中。还有种会议poster的例子，可以参考。</li><li><a href="https://github.com/dair-ai/ml-visuals">ML Visuals</a>:里面包含100多个常用的神经网络的图，是google在线PPT的形式.<a href="https://docs.google.com/presentation/d/11mR1nkIR9fbHegFkcFq8z9oDQ5sjv8E3JJp1LfLGKuk/edit#slide=id.p">PPT直接下载</a></li><li><a href="https://www.iconfont.cn/search/index?searchType=icon&q=%E9%87%91%E5%B8%81&page=1&fromCollection=-1&fills=&tag=">阿里巴巴矢量图标素材库</a></li><li><a href="http://alexlenail.me/NN-SVG/index.html">NN SVG</a>:画神经网络结构用的。左侧是一些设置选项，可以自己设置节点，层数，还有网络类型等等，设置好以后可以把这个神经网络图直接下载下来，然后插入到visio或者PPT中就可以用了！</li><li><code>ChatHub</code>：是一个基于谷歌Chrome浏览器插件的chatbot聚合客户端，你可以用它在一个应用中使用多种AI聊天服务。</li><li><code>Code Interpreter</code>：OpenAI 的官方插件，通过设置中的Beta面板向所有ChatGPT Plus 用户提供。可以数据分析、创建图表、编辑文件、执行数学运算等。可惜要花钱，但它有以下优点：<ul><li>Code Interpreter 允许 AI 做数学题（非常复杂的数学题）和做更精确的文字工作（比如实际计算段落中的字数），因为它可以编写 Python 代码来解决大语言模型在数学和语言方面的固有弱点。</li><li>Code Interpreter 降低了幻觉和迷惑的概率。</li><li>Code Interpreter 让人工智能的用途更加广泛。</li><li>用户不必编程，因为 Code Interpreter 可以代替做所有的工作。</li><li>它给了你更多的 AI Moment。</li></ul></li><li><a href="https://github.com/OpenBMB/MiniCPM-V">视觉问答领域开源项目</a></li></ul><h2 id="2-2-简单聊聊目前对作图的认知"><a href="#2-2-简单聊聊目前对作图的认知" class="headerlink" title="2.2 简单聊聊目前对作图的认知"></a>2.2 简单聊聊目前对作图的认知</h2><p>我感觉审稿人看论文是（就连我自己看论文的时候都是）挑重点看，如果图能把你想表达的观点说清楚，文字写得不好其实问题不大，毕竟文字表达一个个磨非常耗费心力和时间。而且人的注意力天生就是喜欢看图。而且画图其实蛮享受的，它是一个把你的思路显现出来的过程，喜欢。</p><p>但无论是哪种图，配色一般是淡蓝、淡红、淡黄、淡绿四种（彩虹一共才7种颜色，要体现对比就只能是这四种颜色了，而且你需要考虑一下有人红绿色盲 … … ），然后有时会用紫色、灰色补充（紫色多用于模块，灰色多用于小区域或者大面积打底）。整个论文的配色风格需要一致，比如说后面的折线图、柱状图、散点图最好还是以前面框架的颜色一致。</p><p>经过一次投稿，CV感觉只需要两种图，框架图和数据展示图。审美相关，这里安利一下，感觉Yongming Rao老师的图好好看：<br><img src="https://pic4.zhimg.com/80/v2-917d709c464f873d5876ab9665435543_720w.webp"></p><h1 id="3-论文"><a href="#3-论文" class="headerlink" title="3 论文"></a>3 论文</h1><ul><li><a href="http://www.researchrabbitapp.com/">Research Rabbit</a>:文献检索及可视化工具，它使用 AI 帮助我们发现相关且有趣的研究文章, 这些文章是根据我们的研究方向来关联的。<a href="https://zhuanlan.zhihu.com/p/394423702">使用教程</a></li><li><a href="https://www.connectedpapers.com/">connectedpapers</a>:相似论文查找</li><li><a href="https://www.scholar-inbox.com/">scholar-inbox</a>:论文推荐</li></ul><h1 id="4-汇报"><a href="#4-汇报" class="headerlink" title="4 汇报"></a>4 汇报</h1><ul><li><a href="https://zhiwen.xfyun.cn/">讯飞智文-AI在线生成PPT、Word</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Tutorial</category>
      
      <category>Tools</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Tools</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Configure online demo</title>
    <link href="/2024/05/19/onlineDemo/"/>
    <url>/2024/05/19/onlineDemo/</url>
    
    <content type="html"><![CDATA[<p>这篇文章总共纪录了学习Replicate和HuggingFace在线搭demo的过程，最终我选的是HuggingFace，所以HuggingFace的内容详尽一些，Replicate只有一点点。</p><span id="more"></span><h1 id="Replicate"><a href="#Replicate" class="headerlink" title="Replicate"></a>Replicate</h1><p>参考：<a href="https://replicate.com/docs">Replicate文档</a><br>Replicate是一个云端的机器学习模型运行平台，它允许用户使用云端API（在Python或Jupyter Notebook中）直接运行模型，并在云端进行模型的部署和调优。<br>其优势在于：<br>    - 无需下载、安装或配置<br>    - 快速轻松运行机器学习模型<br>    - 提供大量的预训练模型和数据集</p><h2 id="1-1-大致流程"><a href="#1-1-大致流程" class="headerlink" title="1.1 大致流程"></a>1.1 大致流程</h2><p>Replicate的HTTP API 可与任何编程语言配合使用。使用 Python 客户端，首先需要安装Python库：<code>pip install replicate</code>。</p><p>然后去<a href="https://replicate.com/account/api-tokens">account settings</a>中找到你的API token，并把它设置（声明）到你当前的代码环境：<code>export REPLICATE_API_TOKEN=&lt;paste-your-token-here&gt;</code>。</p><p>安全一点的方式为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># get a token: https://replicate.com/account</span><br><span class="hljs-keyword">from</span> getpass <span class="hljs-keyword">import</span> getpass<br><span class="hljs-keyword">import</span> os<br><br>REPLICATE_API_TOKEN = getpass()<br>os.environ[<span class="hljs-string">&quot;REPLICATE_API_TOKEN&quot;</span>] = REPLICATE_API_TOKEN<br><br><span class="hljs-comment">## 2.1 在Python代码中导入Replicate库，以便使用Replicate的功能</span><br><span class="hljs-keyword">import</span> replicate<br><span class="hljs-comment">### receive images as inputs. Use a file handle or URL:</span><br>image = <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;mystery.jpg&quot;</span>, <span class="hljs-string">&quot;rb&quot;</span>)<br><span class="hljs-comment">### or...</span><br>image = <span class="hljs-string">&quot;https://example.com/mystery.jpg&quot;</span><br><br><span class="hljs-comment">## 2.2 调用模型，按需求返回</span><br>replicate.run(<br>  <span class="hljs-string">&quot;replicate/resnet:dd782a3d531b61af491d1026434392e8afb40bfb53b8af35f727e80661489767&quot;</span>,<br>  <span class="hljs-built_in">input</span>=&#123;<span class="hljs-string">&quot;image&quot;</span>: image&#125;<br>)<br></code></pre></td></tr></table></figure><p><a href="https://juejin.cn/post/7298642789078974515">有个跟我很像的用了controlnet的工作在Replicate上的部署教程</a><br>大概了解了一下，感觉Replicate挺简单的，但是好像不如Huggingface的使用者多以及GPU算力要贵一点。决定临阵倒戈，还是去学HuggingFace吧，谁知道以后遇到什么bug了能不能解决。</p><p>好多人用啊，让我看看这个最大的开源平台有多牛(ง๑ •̀_•́)ง</p><h1 id="Gradio-HuggingFace"><a href="#Gradio-HuggingFace" class="headerlink" title="Gradio + HuggingFace"></a>Gradio + HuggingFace</h1><p>计算机视觉和图像处理的算法一般都具有直观的实用性。为了推广自己工作的影响力，大家会选择把自己算法的实现效果部署到网页端的UI接口供大家使用。</p><h1 id="1-界面设计库Gradio"><a href="#1-界面设计库Gradio" class="headerlink" title="1 界面设计库Gradio"></a>1 界面设计库Gradio</h1><p>Gradio是MIT的开源项目，它允许我们快速建立demo或者web application。使用时可理解为一个Python包，Prerequisite: Gradio requires Python 3.8 or higher，它的安装命令：<code>pip install gradio</code>。<br><a href="https://www.gradio.app/guides">Gradio教程</a></p><h2 id="1-1-Quickstart"><a href="#1-1-Quickstart" class="headerlink" title="1.1 Quickstart"></a>1.1 Quickstart</h2><h3 id="1-1-1-示例，实现一个本地静态交互页面"><a href="#1-1-1-示例，实现一个本地静态交互页面" class="headerlink" title="1.1.1 示例，实现一个本地静态交互页面"></a>1.1.1 示例，实现一个本地静态交互页面</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">greet</span>(<span class="hljs-params">name, intensity</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Hello, &quot;</span> + name + <span class="hljs-string">&quot;!&quot;</span> * <span class="hljs-built_in">int</span>(intensity)<br><br>demo = gr.Interface(<br>    fn=greet,<br>    inputs=[<span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;slider&quot;</span>],<br>    outputs=[<span class="hljs-string">&quot;text&quot;</span>],<br>)<br><br>demo.launch()<br><br></code></pre></td></tr></table></figure><p>我用的anaconda命令行运行，它显示：</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs lasso">Running <span class="hljs-keyword">on</span> <span class="hljs-built_in">local</span> URL:  http:<span class="hljs-comment">//127.0.0.1:7860</span><br><br><span class="hljs-keyword">To</span> create a <span class="hljs-keyword">public</span> <span class="hljs-keyword">link</span>, <span class="hljs-built_in">set</span> <span class="hljs-string">`share=True`</span> <span class="hljs-keyword">in</span> <span class="hljs-string">`launch()`</span>.<br></code></pre></td></tr></table></figure><p>然后我在本地浏览器输入<code>http://127.0.0.1:7788/</code>就看到了对应的页面。</p><h3 id="1-1-2-hot-reload-mode"><a href="#1-1-2-hot-reload-mode" class="headerlink" title="1.1.2 hot reload mode"></a>1.1.2 hot reload mode</h3><p>Automatically reloads the Gradio app whenever you make changes to the file. To do this, simply type in gradio before the name of the file instead of python. In the example:<code>gradio app.py</code>(Type this in terminal).<br><a href="https://www.gradio.app/guides/developing-faster-with-reload-mode">Hot Reloading Guide</a></p><h3 id="1-1-3-Understanding-the-Interface-Class"><a href="#1-1-3-Understanding-the-Interface-Class" class="headerlink" title="1.1.3 Understanding the Interface Class"></a>1.1.3 Understanding the Interface Class</h3><p>gradio的核心是它的<code>gr.Interface</code>函数，用来构建可视化界面。The Interface class is designed to create demos for machine learning models which accept one or more inputs, and return one or more outputs.<br>它主要有三个核心属性：</p><ul><li><code>fn</code>: the function to wrap a user interface (UI) around</li><li><code>inputs</code>：the number of components should match the number of arguments in your function</li><li><code>outputs</code>：the number of components should match the number of return values from your function.</li></ul><p>所以对于任何图像处理类的ML代码来说，基本流程就是<strong>图像输入&gt;&gt;模型推理&gt;&gt;返回图片</strong>。<a href="https://www.gradio.app/main/guides/the-interface-class">building Interfaces</a></p><h3 id="1-1-4-Sharing-Your-Demo"><a href="#1-1-4-Sharing-Your-Demo" class="headerlink" title="1.1.4 Sharing Your Demo"></a>1.1.4 Sharing Your Demo</h3><p>Gradio lets you easily share a machine learning demo without having to worry about the hassle of hosting on a web server. Simply set <code>share=True</code> in launch() like <code>demo.launch(share=True)</code>, and a publicly accessible URL will be created for your demo.</p><p>所以实际上他跑起来用的是我本地的算力资源，但是类似网络通信可以将输入输出在不同电脑之间进行联络。Share links expire after 72 hours. (it is also possible to <a href="https://github.com/huggingface/frp/">set up your own Share Server</a> on your own cloud server to overcome this restriction.)</p><h2 id="1-2-the-Interface-Class"><a href="#1-2-the-Interface-Class" class="headerlink" title="1.2 the Interface Class"></a>1.2 the Interface Class</h2><h3 id="1-2-1-Components"><a href="#1-2-1-Components" class="headerlink" title="1.2.1 Components"></a>1.2.1 Components</h3><p>提供了超过30种components(e.g. the gr.Image component is designed to handle input or output images, the gr.Label component displays classification labels and probabilities, the gr.Plot component displays various kinds of plots, and so on).<br>而且Gradio可以自动处理输入输出与函数fn之间的类型转换(Preprocessing and Postprocessing)。</p><h3 id="1-2-2-Components-Attributes"><a href="#1-2-2-Components-Attributes" class="headerlink" title="1.2.2 Components Attributes"></a>1.2.2 Components Attributes</h3><p>比如加一个滑轮效果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 之前的</span><br>demo = gr.Interface(<br>    fn=greet,<br>    inputs=[<span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;slider&quot;</span>],<br>    outputs=[<span class="hljs-string">&quot;text&quot;</span>],<br>)<br><span class="hljs-comment">######################################################################</span><br><span class="hljs-comment"># 现在</span><br>demo = gr.Interface(<br>    fn=greet,<br>    inputs=[<span class="hljs-string">&quot;text&quot;</span>, gr.Slider(value=<span class="hljs-number">2</span>, minimum=<span class="hljs-number">1</span>, maximum=<span class="hljs-number">10</span>, step=<span class="hljs-number">1</span>)],<br>    outputs=[gr.Textbox(label=<span class="hljs-string">&quot;greeting&quot;</span>, lines=<span class="hljs-number">3</span>)],<br>)<br><br></code></pre></td></tr></table></figure><p>Suppose you had a more complex function, with multiple outputs as well. In the example below, we define a function that takes a string, boolean, and number, and returns a string and number.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 之前的</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">greet</span>(<span class="hljs-params">name, intensity</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Hello, &quot;</span> + name + <span class="hljs-string">&quot;!&quot;</span> * intensity<br><br>demo = gr.Interface(<br>    fn=greet,<br>    inputs=[<span class="hljs-string">&quot;text&quot;</span>, gr.Slider(value=<span class="hljs-number">2</span>, minimum=<span class="hljs-number">1</span>, maximum=<span class="hljs-number">10</span>, step=<span class="hljs-number">1</span>)],<br>    outputs=[gr.Textbox(label=<span class="hljs-string">&quot;greeting&quot;</span>, lines=<span class="hljs-number">3</span>)],<br>)<br><span class="hljs-comment"># lines=3 参数用于设置文本框的默认显示行数</span><br><span class="hljs-comment"># 具体来说，它控制了文本框的高度，使其在显示时能够容纳 3 行文本。</span><br><br><span class="hljs-comment">######################################################################</span><br><span class="hljs-comment"># 现在</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">greet</span>(<span class="hljs-params">name, is_morning, temperature</span>):<br>    salutation = <span class="hljs-string">&quot;Good morning&quot;</span> <span class="hljs-keyword">if</span> is_morning <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;Good evening&quot;</span><br>    greeting = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;salutation&#125;</span> <span class="hljs-subst">&#123;name&#125;</span>. It is <span class="hljs-subst">&#123;temperature&#125;</span> degrees today&quot;</span><br>    celsius = (temperature - <span class="hljs-number">32</span>) * <span class="hljs-number">5</span> / <span class="hljs-number">9</span><br>    <span class="hljs-keyword">return</span> greeting, <span class="hljs-built_in">round</span>(celsius, <span class="hljs-number">2</span>)<br><br>demo = gr.Interface(<br>    fn=greet,<br>    inputs=[<span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;checkbox&quot;</span>, gr.Slider(<span class="hljs-number">0</span>, <span class="hljs-number">100</span>)],<br>    outputs=[<span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;number&quot;</span>],<br>)<br></code></pre></td></tr></table></figure><h3 id="1-2-3-Reactive-Interfaces"><a href="#1-2-3-Reactive-Interfaces" class="headerlink" title="1.2.3 Reactive Interfaces"></a>1.2.3 Reactive Interfaces</h3><p>提供Live Interfaces模式，不需要submit button，会自动计算提交结果。暂时我不太需要这个功能，之后遇到再学。</p><h3 id="1-2-4-The-4-Kinds-of-Gradio-Interfaces"><a href="#1-2-4-The-4-Kinds-of-Gradio-Interfaces" class="headerlink" title="1.2.4 The 4 Kinds of Gradio Interfaces"></a>1.2.4 The 4 Kinds of Gradio Interfaces</h3><ol><li>Standard demos: which have both separate inputs and outputs</li><li>Output-only demos: which don’t take any input but produce on output</li><li>Input-only demos: which don’t produce any output but do take in some sort of input</li><li>Unified demos: which have both input and output components, but the input and output components are the same. This means that the output produced overrides the input (e.g. a text autocomplete model)</li></ol><h3 id="1-2-5-Queuing"><a href="#1-2-5-Queuing" class="headerlink" title="1.2.5 Queuing"></a>1.2.5 Queuing</h3><p>Every Gradio app comes with a built-in queuing system that can scale to thousands of concurrent users. You can configure the queue by using <code>queue()</code> method. 例如通过设置queue()的<code>default_concurrency_limit</code>参数来控制单次处理的请求数(默认是1):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">demo = gr.Interface(...).queue(default_concurrency_limit=<span class="hljs-number">5</span>)<br>demo.launch()<br></code></pre></td></tr></table></figure><h3 id="1-2-6-Streaming-outputs"><a href="#1-2-6-Streaming-outputs" class="headerlink" title="1.2.6 Streaming outputs"></a>1.2.6 Streaming outputs</h3><p>In some cases, you may want to stream a sequence of outputs rather than show a single output at once.官网说的场景是“图像生成，显示到结果图像中的每一时刻图像”，感觉我暂时不需要，之后再学。</p><h3 id="1-2-7-Alerts"><a href="#1-2-7-Alerts" class="headerlink" title="1.2.7 Alerts"></a>1.2.7 Alerts</h3><p>跟用户显示警告提醒他们某些输入输出的错误。主要使用<code>gr.Error(&quot;custom message&quot;)</code>、<code>gr.Warning(&quot;custom message&quot;)</code>和<code>gr.Info(&quot;custom message&quot;) </code>。The only difference between gr.Info() and gr.Warning() is the color of the alert.</p><h3 id="1-2-8-Styling"><a href="#1-2-8-Styling" class="headerlink" title="1.2.8 Styling"></a>1.2.8 Styling</h3><p>可以直接调用别人目前设计的主题模板，也可以自己上传CSS文件自定义。只需要在代码中写上这一句<code>demo = gr.Interface(..., theme=gr.themes.Monochrome())</code><br><a href="https://www.gradio.app/guides/theming-guide">关于Theming的介绍</a></p><h3 id="1-2-9-Progress-bars"><a href="#1-2-9-Progress-bars" class="headerlink" title="1.2.9 Progress bars"></a>1.2.9 Progress bars</h3><p>挺人性化的设计的，到哪都是进度条是吧( ´◔︎ ‸◔︎&#96;)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">slowly_reverse</span>(<span class="hljs-params">word, progress=gr.Progress(<span class="hljs-params"></span>)</span>):<br>    progress(<span class="hljs-number">0</span>, desc=<span class="hljs-string">&quot;Starting&quot;</span>)<br>    time.sleep(<span class="hljs-number">1</span>)<br>    progress(<span class="hljs-number">0.05</span>)<br>    new_string = <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-keyword">for</span> letter <span class="hljs-keyword">in</span> progress.tqdm(word, desc=<span class="hljs-string">&quot;Reversing&quot;</span>):<br>        time.sleep(<span class="hljs-number">0.25</span>)<br>        new_string = letter + new_string<br>    <span class="hljs-keyword">return</span> new_string<br><br>demo = gr.Interface(slowly_reverse, gr.Text(), gr.Text())<br><br>demo.launch()<br><br></code></pre></td></tr></table></figure><p> you can even report progress updates automatically from any tqdm.tqdm that already exists within your function by setting the default argument as gr.Progress(track_tqdm&#x3D;True)!</p><h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><p> add example<br>我们可以在页面下方添加供用户选择的测试样例。比如做了一个图像去噪算法，但是用户手头并没有躁点照片，example能让他更快的体验到效果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">greet</span>(<span class="hljs-params">name, intensity</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Hello, &quot;</span> + name + <span class="hljs-string">&quot;!&quot;</span> * <span class="hljs-built_in">int</span>(intensity)<br><br>demo = gr.Interface(<br>    fn=greet,<br>    inputs=[<span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;slider&quot;</span>],<br>    outputs=[<span class="hljs-string">&quot;text&quot;</span>],<br>)<br><br>demo.launch()<br><br></code></pre></td></tr></table></figure><h1 id="2-在线托管平台-HuggingFace"><a href="#2-在线托管平台-HuggingFace" class="headerlink" title="2 在线托管平台 HuggingFace"></a>2 在线托管平台 HuggingFace</h1><p><a href="https://www.gradio.app/guides/sharing-your-app">Hosting on HF Spaces</a><br>在本地测试完成后，接下来就是考虑如何将程序发布到在线平台的问题了。HuggingFace提供了一个项目托管平台，而且能免费提供如Google Colab的在线计算资源。使用服务前，先注册账号（官网界面右上角”Sign Up”）。</p><h2 id="2-1-在线计算空间-Space"><a href="#2-1-在线计算空间-Space" class="headerlink" title="2.1 在线计算空间:Space"></a>2.1 在线计算空间:Space</h2><p>在HuggingFace官网登录账号后，切换到Spaces创建一个新的空间。记得选中”Gradio”和”Public”，以生成一个可公开使用的Gradio在线应用。每个项目空间免费配备8个CPU核和16GB 运行内存，GPU资源需要单独付费。更多关于Spaces的介绍可参考<a href="https://huggingface.co/docs/hub/spaces">官方文档</a>。<br>创建完Space之后，我们需要把本地项目文件（UI构建文件必须得命名成app.py且位于根目录）上传到该空间。具体方法与Github项目的上传和版本维护方式完全一样:</p><ul><li>克隆space项目到本地：<code>git clone https://huggingface.co/spaces/your_account/proj_name/tree/main</code></li><li>将本地已跑通的项目文件复制到刚才克隆的space项目文件夹</li><li>新建描述运行环境依赖的文件：<code>requirements.txt</code></li><li>指定Python依赖的包:<code>packages.txt</code></li><li>指定特殊的系统依赖配置</li><li><a href="https://huggingface.co/docs/hub/spaces-dependencies">详情参考</a></li><li>将此更新同步到远程仓库：<ul><li>git add -A .</li><li>git commit -m “add project files”</li><li>git push</li></ul></li></ul><p>完成以上步骤后（等待1~2分钟系统刷新），进入Space项目的App选项卡即可查看部署到web端的应用。</p><h2 id="2-2-模型托管仓库-Models"><a href="#2-2-模型托管仓库-Models" class="headerlink" title="2.2 模型托管仓库:Models"></a>2.2 模型托管仓库:Models</h2><p>如果我们运行的程序是AI模型，那么一般需要提供一个训练好的checkpoint（一般上百兆）供在线加载。这时，我们可以在HuggingFace的Models页面创建一个与Space项目同名的模型仓库，用于存储需要的checkpoint等文件。</p><ul><li>上传文件：通过上文提到的git方式，或者直接点击已创建的模型页面的Add file</li><li>获取文件路径：例如上传到模型仓库的文件路径是：<code>https://huggingface.co/menghanxia/disco/tree/main/model.pth.tar</code>，其对应的下载路径则需要将tree修改为resolve，即<code>https://huggingface.co/menghanxia/disco/resolve/main/disco-beta.pth.tar</code></li><li>在Space项目的app.py文件中调用文件下载命令:<code>os.system(&quot;wget https://huggingface.co/menghanxia/disco/resolve/main/disco-beta.pth.rar&quot;)</code></li></ul><p><a href="https://huggingface.co/docs/hub/spaces">Spaces文档</a></p>]]></content>
    
    
    <categories>
      
      <category>Tutorial</category>
      
      <category>Tools</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Tools</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch_《Deep learning with PyTorch》</title>
    <link href="/2024/04/22/Pytorch/"/>
    <url>/2024/04/22/Pytorch/</url>
    
    <content type="html"><![CDATA[<p>路漫漫其修远兮。</p><span id="more"></span><p>Reference materials include:</p><ul><li><a href="https://pytorch-cn.readthedocs.io/zh/latest/">PyTorch官方文档(中文版)</a></li><li><a href="https://pytorch.org/tutorials/">Tutorials</a></li><li>Andrew W. Traska撰写的<a href="https://www.manning.com/books/grokking-deep-learning">《Grokking Deep Learning》</a>是开发强大模型和理解深度神经网络基础机制的重要资源</li><li>Ian Goodfellow, Yoshua Bengio和Aaron Courville的<a href="https://www.deeplearningbook.org/">《Deep Learning》</a></li><li>清华翻译的<a href="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/">《Deep learning with PyTorch》</a></li></ul><p>本篇章主要记录的这篇中文教程——&gt;<a href="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/">《Deep learning with PyTorch》</a></p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p><strong>PyTorch是一个使用Python格式实现深度学习模型的库</strong>。它的核心数据结构Tensor，是一个多维数组。Pytorch就像是一个能在GPU上运行并且自带自动求导功能的Numpy数组。它配备了高性能的C++运行引擎使得他不必依赖Python的运行机制：</p><ul><li><strong>Pytorch</strong>的很大部分使用C++和CUDA（NVIDIA提供的类似C++的语言）编写。</li><li><strong>PyTorch</strong>核心是提供多维数组（tensor）的库， torch模块提供了对其进行扩展操作的库。</li><li>同时<strong>PyTorch</strong>的第二个核心功能是允许Tensor跟踪对其所执行的操作，并通过反向传播来计算输出相对于其任何输入的导数。</li></ul><p><strong>PyTorch</strong>最先实现了深度学习架构，深度学习模型强大的原因是因为它可以自动的学习样本输出与所期望输出之间的关系。</p><h2 id="1-1-PyTorch提供了构建和训练神经网络所需的所有模块："><a href="#1-1-PyTorch提供了构建和训练神经网络所需的所有模块：" class="headerlink" title="1.1 PyTorch提供了构建和训练神经网络所需的所有模块："></a>1.1 PyTorch提供了构建和训练神经网络所需的所有模块：</h2><ul><li>构建神经网络的核心模块位于<code>troch.nn</code>中。包括全连接层、卷积层、激活函数和损失函数。</li><li><code>torch.util.data</code>能找到适用于数据加载和处理的工具，相关的两个主要的类为Dataset和DataLoader。<br>  -<code>Dataset</code>承担了自定义的数据格式与标准的Pytorch张量之间的转换任务<br>  -<code>DataLoader</code>可以在后台生成子进程来从Dataset中加载数据，使数据准备就绪并在循环可以使用后立即等待训练循环<br>  -除此之外还可以使用专用的硬件（多个GPU）来训练模型，在这些情况下，可以通过<code>torch.nn.DataParallel</code>和<code>torch.distributed</code>来使用其他的可用硬件</li></ul><p>Pytorch使用Caffe2作为后端，增加了对ONNX的支持（定义了一种与深度学习库无关的模型描述和转换格式），增加了称为<strong>TorchScript</strong>的延迟执行图模式运行引擎（这个模块避开了Python解释器所带来的成本，我们可以将这个模型看作是具有针对张量操作的有限指令集的虚拟机，它的调用不会增加Python的开销，还能使PyTorch可以实时地将已知序列转换为更有效的混合操作）。默认的运行方式是即使执行（eager mode）。</p><p><strong>关于PyTorch的安装，windows建议使用Anaconda，Linux建议使用Pip。</strong></p><h1 id="2-从张量开始"><a href="#2-从张量开始" class="headerlink" title="2. 从张量开始"></a>2. 从张量开始</h1><p><strong>- Tensor是Pytorch最基本的数据结构</strong></p><p>深度学习的应用往往是将某种形式获取的数据（图像或文本）转换为另一种形式的数据（标签、数字或文本），因此从这个角度看，深度学习就像是构建一个将数据从一种表示转换为另一种表示的系统，这种转换是通过从一系列样本中提取共性来驱动的额，这些共性能够反映期望的映射关系。<br>为了实现上述过程，首先需要让网路理解输入数据，因此输入需要被转换为浮点数的集合。这些浮点数的集合及其操作是现代AI的核心。而网络层次之间的数据被视为中间表示（intermediate representation）。中间表示是将输入与前一层神经元权重相结合的结果，每个中间表示对于之前的输入都是唯一的。<br>为此，PyTorch引入了一个基本的数据结构：张量（tensor）。张量是指将向量（vector）和矩阵（matrix）推广到任意维度，与张量相同概念的另一个名称是多维数组（multidimensional array）。</p><h2 id="2-1-张量基础"><a href="#2-1-张量基础" class="headerlink" title="2.1 张量基础"></a>2.1 张量基础</h2><p>Python列表或数字元组（tuple）是在内存中单独分配的Python对象的集合；而PyTorch张量或NumPy数组（通常）是连续内存块上的视图（view），这些内存块存有未封装（unboxed）的C数值类型。<br><strong>获取一个张量的形状：tensor.shape</strong></p><h2 id="2-2-张量与存储"><a href="#2-2-张量与存储" class="headerlink" title="2.2 张量与存储"></a>2.2 张量与存储</h2><p>基础内存只分配一次，由torch.Storage实例管理，<strong>Storage是一个一维的数值数据数组</strong>，例如一块包含了指定类型（可能是float或int32）数字的连续内存块。<strong>而tensor可以看作是某个Storage实例的视图。</strong>因此多个tensor可以索引到同一Storage。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br>points = torch.tensor([[<span class="hljs-number">1.0</span>, <span class="hljs-number">4.0</span>], [<span class="hljs-number">2.0</span>, <span class="hljs-number">1.0</span>], [<span class="hljs-number">3.0</span>, <span class="hljs-number">5.0</span>]])<br>points.storage()<br><br><span class="hljs-comment"># 输出</span><br> <span class="hljs-number">1.0</span><br> <span class="hljs-number">4.0</span><br> <span class="hljs-number">2.0</span><br> <span class="hljs-number">1.0</span><br> <span class="hljs-number">3.0</span><br> <span class="hljs-number">5.0</span><br>[torch.FloatStorage of size <span class="hljs-number">6</span>]<br></code></pre></td></tr></table></figure><p> <strong>无法使用两个索引来索引二维tensor的存储，因为Storage始终是一维的，与引用它的任何张量的维数无关。</strong><br><img src="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/img/chapter2/2.4.png" alt="张量是一个存储实例的视图"></p><h2 id="2-3-尺寸、存储偏移与步长"><a href="#2-3-尺寸、存储偏移与步长" class="headerlink" title="2.3 尺寸、存储偏移与步长"></a>2.3 尺寸、存储偏移与步长</h2><p><img src="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/img/chapter2/2.5.png" alt="张量的尺寸、偏移与步长之间的关系"><br>tensor可以看作是某个Storage实例的视图。为了索引Storage，张量依赖于几条明确定义它们的信息：尺寸（size）、存储偏移（storage offset）和步长（stride）<br>    - 尺寸是一个元组，表示tensor每个维度上有多少个元素。<br>    - 存储偏移是Storage中与张量中的第一个元素相对应的索引。<br>        - 步长是在Storage中为了沿每个维度获取下一个元素而需要跳过的元素数量。<br>        - 步长是一个元组，表示当索引在每个维度上增加1时必须跳过的存储中元素的数量。<br>    - shape是属性，size()是类，这俩包含的信息相同。</p><p>用下标<code>i</code>和<code>j</code>访问二维张量等价于访问存储中的<code>storage_offset + stride[0] * i + stride[1] * j</code>元素。<br>张量Tensor和和存储Storage之间的这种间接操作会使某些操作（例如转置或提取子张量）的代价很小，因为<strong>它们不会导致内存重新分配</strong>；相反，它们（仅仅）分配一个新的张量对象，该对象具有不同的尺寸、存储偏移或步长。更改子张量同时也会对原始张量产生影响。所以我们可以克隆子张量得到新的张量（以避免这种影响）：<code>tensor.clone()</code>.Tensor的转置只改变尺寸和步长。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">some_tensor = torch.ones(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>)<br>some_tensor.shape, some_tensor.stride()<br><span class="hljs-comment"># 输出</span><br>(torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]), (<span class="hljs-number">20</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>))<br><br>some_tensor_t = some_tensor.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>)<br>some_tensor_t.shape, some_tensor_t.stride()<br><span class="hljs-comment"># 输出</span><br>(torch.Size([<span class="hljs-number">5</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>]), (<span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">20</span>))<br><br></code></pre></td></tr></table></figure><h2 id="2-4-数据类型"><a href="#2-4-数据类型" class="headerlink" title="2.4 数据类型"></a>2.4 数据类型</h2><ul><li>torch.float32&#x2F;torch.float —— 32位浮点数:torch.FloatTensor &#x3D; torch.Tensor</li><li>torch.float64&#x2F;torch.double —— 64位双精度浮点数:torch.DoubleTensor</li><li>torch.float16&#x2F;torch.half —— 16位半精度浮点数</li><li>torch.int8 —— 带符号8位整数:torch.CharTensor</li><li>torch.uint8 —— 无符号8位整数:torch.ByteTensor</li><li>torch.int16&#x2F;torch.short —— 带符号16位整数</li><li>torch.int32&#x2F;torch.int —— 带符号32位整数</li><li>torch.int64&#x2F;torch.long —— 带符号64位整数</li></ul><p>通过访问<code>dtype</code>属性来获得张量的数据类型。而数据类型之间的转换可以通过<code>type</code>和<code>to</code>实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">short_points = torch.ones(<span class="hljs-number">10</span>, <span class="hljs-number">2</span>).short()<br>short_points = torch.ones(<span class="hljs-number">10</span>, <span class="hljs-number">2</span>).to(dtype=torch.short)<br></code></pre></td></tr></table></figure><h2 id="2-5-索引张量"><a href="#2-5-索引张量" class="headerlink" title="2.5 索引张量"></a>2.5 索引张量</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">some_list = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>))<br>some_list[:]     <span class="hljs-comment"># 所有元素</span><br>some_list[<span class="hljs-number">1</span>:<span class="hljs-number">4</span>]   <span class="hljs-comment"># 第1（含）到第4（不含）个元素</span><br>some_list[<span class="hljs-number">1</span>:]    <span class="hljs-comment"># 第1（含）个之后所有元素</span><br>some_list[:<span class="hljs-number">4</span>]    <span class="hljs-comment"># 第4（不含）个之前所有元素</span><br>some_list[:-<span class="hljs-number">1</span>]   <span class="hljs-comment"># 最末尾（不含）元素之前所有元素</span><br>some_list[<span class="hljs-number">1</span>:<span class="hljs-number">4</span>:<span class="hljs-number">2</span>] <span class="hljs-comment"># 范围1（含）到4（不含），步长为2的元素</span><br><br>points[<span class="hljs-number">1</span>:]    <span class="hljs-comment"># 第1行及之后所有行，（默认）所有列</span><br>points[<span class="hljs-number">1</span>:, :] <span class="hljs-comment"># 第1行及之后所有行，所有列</span><br>points[<span class="hljs-number">1</span>:, <span class="hljs-number">0</span>] <span class="hljs-comment"># 第1行及之后所有行，仅第0列</span><br><br></code></pre></td></tr></table></figure><h2 id="2-6-Pytorch与NumPy的互通性"><a href="#2-6-Pytorch与NumPy的互通性" class="headerlink" title="2.6 Pytorch与NumPy的互通性"></a>2.6 Pytorch与NumPy的互通性</h2><p>从PyTorch张量创建NumPy数组：<code>points_np = points.numpy()</code><br>从NumPy数组创建PyTorch张量：<code>points = torch.from_numpy(points_np)</code></p><h2 id="2-7-序列化张量"><a href="#2-7-序列化张量" class="headerlink" title="2.7 序列化张量"></a>2.7 序列化张量</h2><p>PyTorch内部使用<code>pickle</code>来序列化张量对象和实现用于存储的专用序列化代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 将points张量保存到ourpoints.t文件中</span><br>torch.save(points, <span class="hljs-string">&#x27;../../data/chapter2/ourpoints.t&#x27;</span>)<br><span class="hljs-comment"># 将points加载回来</span><br>points = torch.load(<span class="hljs-string">&#x27;../../data/chapter2/ourpoints.t&#x27;</span>)<br><br><span class="hljs-comment">## 上述例子可让你快速保存张量，但这个文件格式本身是不互通的，你只能用PyTorch读取它</span><br><span class="hljs-comment">## 对于需要（互通）的情况，你可以使用HDF5格式和库</span><br><span class="hljs-comment">## HDF5是一种可移植的、广泛支持的格式，用于表示以嵌套键值字典形式组织的序列化多维数组。</span><br><span class="hljs-comment">## Python通过h5py库支持HDF5，该库以NumPy数组的形式接收和返回数据。</span><br><br><span class="hljs-keyword">import</span> h5py<br><br>f = h5py.File(<span class="hljs-string">&#x27;../../data/chapter2/ourpoints.hdf5&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>)<br>dset = f.create_dataset(<span class="hljs-string">&#x27;coords&#x27;</span>, data=points.numpy())<br>f.close()<br><span class="hljs-comment"># coords是传入HDF5文件的键值</span><br><span class="hljs-comment"># 你可以索引在磁盘的数据并且仅访问你感兴趣的元素，例如你只想加载数据集中的最后两个点数据：</span><br>f = h5py.File(<span class="hljs-string">&#x27;../../data/chapter2/ourpoints.hdf5&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>)<br>dset = f[<span class="hljs-string">&#x27;coords&#x27;</span>]<br>last_points = dset[<span class="hljs-number">1</span>:]<br><br></code></pre></td></tr></table></figure><h2 id="2-8-将张量转移到GPU上运行"><a href="#2-8-将张量转移到GPU上运行" class="headerlink" title="2.8 将张量转移到GPU上运行"></a>2.8 将张量转移到GPU上运行</h2><p>PyTorch张量还具有设备（device）的概念，这是在设置计算机上放张量（tensor）数据的位置。</p><ul><li>通过为构造函数指定相应的参数，可以在GPU上创建张量：<code>points_gpu = torch.tensor([[1.0, 4.0], [2.0, 1.0], [3.0, 4.0]], device=&#39;cuda&#39;)</code>；同时可以通过提供device和dtype参数来同时更改位置和数据类型</li><li>也可以使用<code>to</code>方法将在CPU上创建的张量（tensor）复制到GPU：<code>points_gpu = points.to(device=&#39;cuda&#39;)</code></li><li>使用速记方法<code>cpu</code>和<code>cuda</code>代替to方法来实现相同的目标：<code>points_gpu = points.cuda(0)</code>和<code>points_cpu = points_gpu.cpu()</code></li></ul><h1 id="3-使用张量表示真实数据"><a href="#3-使用张量表示真实数据" class="headerlink" title="3 使用张量表示真实数据"></a>3 使用张量表示真实数据</h1><p>将异构的现实世界数据编码成浮点数张量以供神经网络使用。</p><ul><li>表格数据：表格中的每一行都独立于其他行，他们的顺序页没有任何关系</li><li>时间序列：存在严格的排序其他类型的数据。比如文本和音频。</li><li>文本数据：将文本信息编码为张量形式的技术为独热编码。<br>每个字符将由一个长度等于编码中字符数的向量表示。该向量除了有一个元素是1外其他全为0，这个1的索引对应该字符在字符集中的位置。接下来，在编码中建立单词到索引的映射，一般单词作为键，而整数作为值。独热编码时，你将使用此词典来有效地找到单词的索引。但由于独热编码不支持长篇文本，后续出现了嵌入的方式处理文本。<br><strong>【关于文本嵌入】</strong><br>用于同一上下文的单词映射到嵌入空间的邻近区域。生成的嵌入的一个有趣的方面是，相似的词不仅会聚在一起，还会与其他词保持一致的空间关系。如果你要使用“苹果”的嵌入向量，并加上和减去其他词的嵌入向量，就可以进行类比，例如<code>苹果 - 红色 - 甜 + 酸</code>，最后可能得到一个类似<code>柠檬</code>的向量。</li><li>图像数据：图像表示为按规则网格排列的标量集合。PyTorch模块处理图像数据需要将张量设置为C x H x W（分别为通道、高度和宽度）</li><li>体积数据：在CT（Computed Tomography）扫描等医学成像应用程序的情况下，通常需要处理从头到脚方向堆叠的图像序列，每个序列对应于整个身体的横截面。在CT扫描中，强度代表身体不同部位的密度：肺、脂肪、水、肌肉、骨骼，以密度递增的顺序排列，当在临床工作站上显示CT扫描时，会从暗到亮映射。根据穿过人体后到达检测器的X射线量计算每个点的密度，并使用一些复杂的数学运算将原始传感器数据反卷积（deconvolve）为完整体积数据。CT具有单个的强度通道，这类似于灰度图像。通过将单个2D切片堆叠到3D张量中，你可以构建表示对象的3D解剖结构的体积数据。</li></ul><h1 id="4-学习机制"><a href="#4-学习机制" class="headerlink" title="4 学习机制"></a>4 学习机制</h1><p>数据科学的流程</p><ul><li>得到很多好的数据</li><li>试图将这些数据可视化</li><li>选择有可能拟合数据的最简单的模型</li><li>划分数据，以便处理部分数据并保留独立的数据集用来验证</li><li>从试探性的偏心率和大小开始，然后进行迭代直到模型拟合观察结果为止</li><li>根据独立的数据集验证他的模型</li></ul><p><img src="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/img/chapter4/4.2.png" alt="模型的学习过程"></p><h2 id="4-1-一个反向传播的简单示例"><a href="#4-1-一个反向传播的简单示例" class="headerlink" title="4.1 一个反向传播的简单示例"></a>4.1 一个反向传播的简单示例</h2><p>通过链式法则向后传播导数，可以计算复合函数（模型函数和损失函数）相对于它们的最内层参数<code>w</code>和<code>b</code>的梯度。基本的要求是涉及到的函数都是可微分的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">model</span>(<span class="hljs-params">t_u, w, b</span>):<br>    <span class="hljs-keyword">return</span> w * t_u + b<br><br><span class="hljs-comment"># 定义损失函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss_fn</span>(<span class="hljs-params">t_p, t_c</span>):<br>    squared_diffs = (t_p - t_c)**<span class="hljs-number">2</span><br>    <span class="hljs-keyword">return</span> squared_diffs.mean()<br><br><span class="hljs-comment"># 导数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dmodel_dw</span>(<span class="hljs-params">t_u, w, b</span>):<br>    <span class="hljs-keyword">return</span> t_u<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dmodel_db</span>(<span class="hljs-params">t_u, w, b</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1.0</span><br><br><span class="hljs-comment"># 返回相对于 w 和 b 的梯度的函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_fn</span>(<span class="hljs-params">t_u, t_c, t_p, w, b</span>):<br>    dloss_dw = dloss_fn(t_p, t_c) * dmodel_dw(t_u, w, b)<br>    dloss_db = dloss_fn(t_p, t_c) * dmodel_db(t_u, w, b)<br>    <span class="hljs-keyword">return</span> torch.stack([dloss_dw.mean(), dloss_db.mean()])<br><br><span class="hljs-comment"># 循环训练</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">training_loop</span>(<span class="hljs-params">n_epochs, learning_rate, params, t_u, t_c, </span><br><span class="hljs-params">                    print_params = <span class="hljs-literal">True</span>, verbose=<span class="hljs-number">1</span></span>):<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n_epochs + <span class="hljs-number">1</span>):<br>        w, b = params<br><br>        t_p = model(t_u, w, b) <span class="hljs-comment"># 前向传播</span><br>        loss = loss_fn(t_p, t_c)<br>        grad = grad_fn(t_u, t_c, t_p, w, b) <span class="hljs-comment"># 反向传播</span><br><br>        params = params - learning_rate * grad<br><br>        <span class="hljs-keyword">if</span> epoch % verbose == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Epoch %d, Loss %f&#x27;</span> % (epoch, <span class="hljs-built_in">float</span>(loss)))<br>            <span class="hljs-keyword">if</span> print_params:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;    Params: &#x27;</span>, params)<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;    Grad  : &#x27;</span>, grad)<br>    <span class="hljs-keyword">return</span> params<br><br></code></pre></td></tr></table></figure><h2 id="4-2-Pytorch自动求导"><a href="#4-2-Pytorch自动求导" class="headerlink" title="4.2 Pytorch自动求导"></a>4.2 Pytorch自动求导</h2><p>一般来讲，所有PyTorch张量都有一个初始为空的名为<code>grad</code>的属性:<code>params.grad is None # True</code>。你可以将包含任意数量的张量的<code>require_grad</code>设置为<code>True</code>以及组合任何函数。在这种情况下，PyTorch会在沿着整个函数链（即计算图）计算损失的导数，并在这些张量（即计算图的叶节点）的grad属性中将这些导数值累积（accumulate）起来。<br><strong>!!!!【Attention】</strong><br>重复调用backward会导致导数在叶节点处累积。因此，如果提前调用了backward，然后再次计算损失并再次调用backward（如在训练循环中一样），那么在每个叶节点上的梯度会被累积（即求和）在前一次迭代计算出的那个叶节点上，导致梯度值不正确。为防止这种情况发生，你需要在每次迭代时将梯度显式清零:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> params.grad <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>    params.grad.zero_()<br></code></pre></td></tr></table></figure><p>torch模块有一个optim子模块，你可以在其中找到实现不同优化算法的类。这里有一个简短的清单：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-built_in">dir</span>(optim)<br><br><span class="hljs-comment"># 输出</span><br>[<span class="hljs-string">&#x27;ASGD&#x27;</span>,<br> <span class="hljs-string">&#x27;Adadelta&#x27;</span>,<br> <span class="hljs-string">&#x27;Adagrad&#x27;</span>,<br> <span class="hljs-string">&#x27;Adam&#x27;</span>,<br> <span class="hljs-string">&#x27;AdamW&#x27;</span>,<br> <span class="hljs-string">&#x27;Adamax&#x27;</span>,<br> <span class="hljs-string">&#x27;LBFGS&#x27;</span>,<br> <span class="hljs-string">&#x27;Optimizer&#x27;</span>,<br> <span class="hljs-string">&#x27;RMSprop&#x27;</span>,<br> <span class="hljs-string">&#x27;Rprop&#x27;</span>,<br> <span class="hljs-string">&#x27;SGD&#x27;</span>,<br> <span class="hljs-string">&#x27;SparseAdam&#x27;</span>,<br> ...<br>]<br></code></pre></td></tr></table></figure><p>深度神经网络可以近似复杂的函数，前提是神经元的数量（即参数量）足够高。参数越少，网络能够近似的函数越简单。因此，这里有一条规律：如果训练损失没有减少，则该模型对于数据来说太简单了。另一种可能性是训练数据中不包含有意义的信息以用于预测输出。<br><img src="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/img/chapter4/4.12.png" alt="关于过拟合的举例"></p><h1 id="5-使用神经网络拟合数据"><a href="#5-使用神经网络拟合数据" class="headerlink" title="5 使用神经网络拟合数据"></a>5 使用神经网络拟合数据</h1><p>不管具体模型是什么，参数的更新方式都是一样的：反向传播误差然后通过计算损失关于参数的梯度来更新这些参数。神经网络具有非凸误差曲面主要是因为激活函数。组合神经元来逼近各种复杂函数的能力取决于每个神经元固有的线性和非线性行为的组合。深度神经网络可让你近似高度非线性的过程，而无需为它们建立明确的模型。</p><h2 id="5-1-神经元"><a href="#5-1-神经元" class="headerlink" title="5.1 神经元"></a>5.1 神经元</h2><p>深度学习的核心是神经网络，即能够通过简单函数的组合来表示复杂函数的数学实体。这些复杂函数的基本组成单元是神经元，如图5.2所示。从本质上讲，神经元不过是输入的线性变换（例如，输入乘以一个数[weight，权重]，再加上一个常数[偏置，bias]），然后再经过一个固定的非线性函数（称为激活函数）。<br><img src="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/img/chapter5/5.2.png" alt="神经元：线性变换后再经过一个非线性函数"><br><img src="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/img/chapter5/5.3.png" alt="一个三层的神经网络"></p><h2 id="5-2-激活函数"><a href="#5-2-激活函数" class="headerlink" title="5.2 激活函数"></a>5.2 激活函数</h2><p>激活函数的作用是将先前线性运算的输出聚集到给定范围内。一系列线性变换紧跟可微激活函数中可以构建出能近似高度非线性过程的模型，且可以通过梯度下降很好地估计出其参数。<br>激活函数的要求有：</p><ul><li>非线性</li><li>可微<br><img src="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/img/chapter5/5.5.png" alt="常用以及不是很常用的激活函数"></li></ul><h2 id="5-3-PyTorch的nn模块"><a href="#5-3-PyTorch的nn模块" class="headerlink" title="5.3 PyTorch的nn模块"></a>5.3 PyTorch的nn模块</h2><p>PyTorch有一个专门用于神经网络的完整子模块：<code>torch.nn</code>。该子模块包含创建各种神经网络体系结构所需的构建块。这些构建块在PyTorch术语中称为module（模块），在其他框架中称为layer（层）。nn中的任何模块都被编写成同时产生一个批次（即多个输入）的输出。这样进行批处理的主要原因是希望可以充分利用执行计算的计算资源。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 1. nn提供了一种通过nn.Sequential容器串联模块的简单方法</span><br>seq_model = nn.Sequential(<br>            nn.Linear(<span class="hljs-number">1</span>, <span class="hljs-number">13</span>),<br>            nn.Tanh(),<br>            nn.Linear(<span class="hljs-number">13</span>, <span class="hljs-number">1</span>))<br>seq_model<br><span class="hljs-comment">## 输出</span><br>Sequential(<br>  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">1</span>, out_features=<span class="hljs-number">13</span>, bias=<span class="hljs-literal">True</span>)<br>  (<span class="hljs-number">1</span>): Tanh()<br>  (<span class="hljs-number">2</span>): Linear(in_features=<span class="hljs-number">13</span>, out_features=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>)<br>)<br><span class="hljs-comment"># ——————————————————————————————————————————————————————————————————</span><br><br><span class="hljs-comment">## 1.1 Sequential中每个模块的名称都是该模块在参数中出现的顺序。</span><br><span class="hljs-comment">##      有趣的是，Sequential还可以接受OrderedDict作为参数</span><br><span class="hljs-comment">#       这样就可以给Sequential的每个模块命名</span><br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> OrderedDict<br><br>seq_model = nn.Sequential(OrderedDict([<br>    (<span class="hljs-string">&#x27;hidden_linear&#x27;</span>, nn.Linear(<span class="hljs-number">1</span>, <span class="hljs-number">8</span>)),<br>    (<span class="hljs-string">&#x27;hidden_activation&#x27;</span>, nn.Tanh()),<br>    (<span class="hljs-string">&#x27;output_linear&#x27;</span>, nn.Linear(<span class="hljs-number">8</span>, <span class="hljs-number">1</span>))<br>]))<br><br>seq_model<br><span class="hljs-comment">## 输出</span><br>Sequential(<br>  (hidden_linear): Linear(in_features=<span class="hljs-number">1</span>, out_features=<span class="hljs-number">8</span>, bias=<span class="hljs-literal">True</span>)<br>  (hidden_activation): Tanh()<br>  (output_linear): Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>)<br>)<br><span class="hljs-comment"># ——————————————————————————————————————————————————————————————————</span><br><br><br><span class="hljs-comment"># 2. 调用model.parameters()可以得到第一线性模块和第二线性模块中的权重和偏差。</span><br><span class="hljs-comment">## 在本例中，我们可以通过打印形状来检查参数：</span><br>[param.shape <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> seq_model.parameters()]<br><br><span class="hljs-comment">## 输出</span><br>[torch.Size([<span class="hljs-number">13</span>, <span class="hljs-number">1</span>]), torch.Size([<span class="hljs-number">13</span>]), torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">13</span>]), torch.Size([<span class="hljs-number">1</span>])]<br><span class="hljs-comment"># ——————————————————————————————————————————————————————————————————</span><br><br><span class="hljs-comment"># 3. 当你检查由几个子模块组成的模型的参数时，可以方便地通过其名称识别参数。这个方法叫做named_parameters</span><br><span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> seq_model.named_parameters():<br>    <span class="hljs-built_in">print</span>(name, param.shape)<br><br><span class="hljs-comment">##  输出</span><br><span class="hljs-number">0.</span>weight torch.Size([<span class="hljs-number">13</span>, <span class="hljs-number">1</span>])<br><span class="hljs-number">0.</span>bias torch.Size([<span class="hljs-number">13</span>])<br><span class="hljs-number">2.</span>weight torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">13</span>])<br><span class="hljs-number">2.</span>bias torch.Size([<span class="hljs-number">1</span>])<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Tutorial</category>
      
      <category>PyTorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
