<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Exploring the PyTorch Journey with a Deeper Dive</title>
    <link href="/2024/04/22/Pytoch/"/>
    <url>/2024/04/22/Pytoch/</url>
    
    <content type="html"><![CDATA[<p>路漫漫其修远兮。</p><span id="more"></span><p>It’s ashamed to realized the importance of systematically learning PyTorch now. However, there will never be an earlier time than today, so I will try my best start learning from now on. Reference materials include:</p><ul><li><a href="https://pytorch-cn.readthedocs.io/zh/latest/">PyTorch官方文档(中文版)</a></li><li><a href="https://pytorch.org/tutorials/">tutorials</a></li><li><a href="https://tangshusen.me/Deep-Learning-with-PyTorch-Chinese/">PyTorch教程书《Deep learning with PyTorch》</a></li></ul><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p><strong>PyTorch是一个使用Python格式实现深度学习模型的库</strong>。它的核心数据结构Tensor，是一个多维数组。Pytorch就像是一个能在GPU上运行并且自带自动求导功能的Numpy数组。它配备了高性能的C++运行引擎使得他不必依赖Python的运行机制：</p><ul><li><strong>Pytorch</strong>的很大部分使用C++和CUDA（NVIDIA提供的类似C++的语言）编写。</li><li><strong>PyTorch</strong>核心是提供多维数组（tensor）的库， torch模块提供了对其进行扩展操作的库。</li><li>同时<strong>PyTorch</strong>的第二个核心功能是允许Tensor跟踪对其所执行的操作，并通过反向传播来计算输出相对于其任何输入的导数。</li></ul><p><strong>PyTorch</strong>最先实现了深度学习架构，深度学习模型强大的原因是因为它可以自动的学习样本输出与所期望输出之间的关系。</p><h3 id="1-1-PyTorch提供了构建和训练神经网络所需的所有模块："><a href="#1-1-PyTorch提供了构建和训练神经网络所需的所有模块：" class="headerlink" title="1.1 PyTorch提供了构建和训练神经网络所需的所有模块："></a>1.1 PyTorch提供了构建和训练神经网络所需的所有模块：</h3><ul><li>构建神经网络的核心模块位于<code>troch.nn</code>中。包括全连接层、卷积层、激活函数和损失函数。</li><li><code>torch.util.data</code>能找到适用于数据加载和处理的工具，相关的两个主要的类为Dataset和DataLoader。<br>  -<code>Dataset</code>承担了自定义的数据格式与标准的Pytorch张量之间的转换任务<br>  -<code>DataLoader</code>可以在后台生成子进程来从Dataset中加载数据，使数据准备就绪并在循环可以使用后立即等待训练循环<br>  -除此之外还可以使用专用的硬件（多个GPU）来训练模型，在这些情况下，可以通过<code>torch.nn.DataParallel</code>和<code>torch.distributed</code>来使用其他的可用硬件</li></ul><p>Pytorch使用Caffe2作为后端，增加了对ONNX的支持（定义了一种与深度学习库无关的模型描述和转换格式），增加了称为<strong>TorchScript</strong>的延迟执行图模式运行引擎（这个模块避开了Python解释器所带来的成本，我们可以将这个模型看作是具有针对张量操作的有限指令集的虚拟机，它的调用不会增加Python的开销，还能使PyTorch可以实时地将已知序列转换为更有效的混合操作）。默认的运行方式是即使执行（eager mode）。</p><p><strong>关于PyTorch的安装，windows建议使用Anaconda，Linux建议使用Pip。</strong></p><!-- ### Run server<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a> –&gt;<br> –&gt;</p>]]></content>
    
    
    
    <tags>
      
      <tag>code</tag>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
